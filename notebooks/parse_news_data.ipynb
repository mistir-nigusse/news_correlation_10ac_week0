{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten websites with the largest counts of news articles: \n",
      "source_name\n",
      "ETF Daily News        16746\n",
      "The Times of India     7504\n",
      "GlobeNewswire          5423\n",
      "Globalsecurity.org     3119\n",
      "Forbes                 2784\n",
      "BBC News               2113\n",
      "ABC News               2058\n",
      "Business Insider       2034\n",
      "The Punch              1800\n",
      "Al Jazeera English     1664\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Bottom ten websites with the smallest counts of news articles: \n",
      "source_name\n",
      "CNA                            674\n",
      "Time                           600\n",
      "Android Central                522\n",
      "Gizmodo.com                    388\n",
      "ReadWrite                      324\n",
      "Euronews                       286\n",
      "Wired                          270\n",
      "CNN                            267\n",
      "The Verge                      214\n",
      "AllAfrica - Top Africa News     20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = '../data' \n",
    "articles_df = pd.read_csv(f\"{data_dir}/rating.csv\") \n",
    "\n",
    "website_article_counts = articles_df['source_name'].value_counts()\n",
    "\n",
    "top_ten_websites = website_article_counts.head(10)\n",
    "bottom_ten_websites = website_article_counts.tail(10)\n",
    "\n",
    "print(\"Top ten websites with the largest counts of news articles: \")\n",
    "print(top_ten_websites)\n",
    "print(\"\\nBottom ten websites with the smallest counts of news articles: \")\n",
    "print(bottom_ten_websites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten Websites with the Highest Traffic:\n",
      "Domain\n",
      "toyotamusicfactory.com    1000000\n",
      "soderhomes.com             999999\n",
      "pinkwater.com              999998\n",
      "mt-lock.com                999997\n",
      "kireie.com                 999996\n",
      "keith-baker.com            999995\n",
      "irishcycle.com             999994\n",
      "hmag.com                   999993\n",
      "exploring-africa.com       999992\n",
      "eiretrip.com               999991\n",
      "Name: GlobalRank, dtype: int64\n",
      "\n",
      "Bottom Ten Websites with the Lowest Traffic:\n",
      "Domain\n",
      "google.com               1\n",
      "facebook.com             2\n",
      "youtube.com              3\n",
      "twitter.com              4\n",
      "instagram.com            5\n",
      "linkedin.com             6\n",
      "apple.com                7\n",
      "microsoft.com            8\n",
      "googletagmanager.com     9\n",
      "wikipedia.org           10\n",
      "Name: GlobalRank, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the traffic data\n",
    "data_dir = '../data'  # Adjust path as per your directory structure\n",
    "traffic_df = pd.read_csv(f\"{data_dir}/traffic.csv\")\n",
    "\n",
    "# Calculate traffic counts for each website\n",
    "website_traffic_counts = traffic_df.groupby('Domain')['GlobalRank'].min()\n",
    "\n",
    "# Get the top and bottom ten websites\n",
    "top_ten_websites_traffic = website_traffic_counts.nlargest(10)\n",
    "bottom_ten_websites_traffic = website_traffic_counts.nsmallest(10)\n",
    "\n",
    "# Print top ten websites with highest traffic\n",
    "print(\"Top Ten Websites with the Highest Traffic:\")\n",
    "print(top_ten_websites_traffic)\n",
    "\n",
    "# Print bottom ten websites with lowest traffic\n",
    "print(\"\\nBottom Ten Websites with the Lowest Traffic:\")\n",
    "print(bottom_ten_websites_traffic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten Countries with the Highest Number of News Media Organizations:\n",
      "Country\n",
      "United States     14111\n",
      "United Kingdom     1950\n",
      "Italy              1810\n",
      "France             1041\n",
      "Russia             1024\n",
      "Canada              887\n",
      "Germany             884\n",
      "China               780\n",
      "Turkey              725\n",
      "India               686\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Bottom Ten Countries with the Lowest Number of News Media Organizations:\n",
      "Country\n",
      "Greenland         1\n",
      "Guernsey          1\n",
      "Isle of Man       1\n",
      "Cook Islands      1\n",
      "Guinea-Bissau     1\n",
      "Micronesia        1\n",
      "Aruba             1\n",
      "American Samoa    1\n",
      "Guadeloupe        1\n",
      "Saint Helena      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the domain location data\n",
    "data_dir = '../data'  # Adjust path as per your directory structure\n",
    "domains_location_df = pd.read_csv(f\"{data_dir}/domains_location.csv\")\n",
    "\n",
    "# Calculate the count of domains for each country\n",
    "country_domain_counts = domains_location_df['Country'].value_counts()\n",
    "\n",
    "# Get the top and bottom ten countries\n",
    "top_ten_countries = country_domain_counts.head(10)\n",
    "bottom_ten_countries = country_domain_counts.tail(10)\n",
    "\n",
    "# Print top ten countries with the highest number of news media organizations\n",
    "print(\"Top Ten Countries with the Highest Number of News Media Organizations:\")\n",
    "print(top_ten_countries)\n",
    "\n",
    "# Print bottom ten countries with the lowest number of news media organizations\n",
    "print(\"\\nBottom Ten Countries with the Lowest Number of News Media Organizations:\")\n",
    "print(bottom_ten_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten Countries with Many Articles Written About Them:\n",
      "             Count\n",
      "US            2321\n",
      "China         1062\n",
      "Ukraine       1023\n",
      "Russia         733\n",
      "Africa         488\n",
      "EU             283\n",
      "Middle East    186\n",
      "\n",
      "Bottom Ten Countries with Few Articles Written About Them:\n",
      "             Count\n",
      "Middle East    186\n",
      "EU             283\n",
      "Africa         488\n",
      "Russia         733\n",
      "Ukraine       1023\n",
      "China         1062\n",
      "US            2321\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the data containing articles\n",
    "data_dir = '../data'  # Adjust path as per your directory structure\n",
    "articles_df = pd.read_csv(f\"{data_dir}/rating.csv\")  # Assuming the dataset is in CSV format\n",
    "\n",
    "# Extract mentions of countries from the article content\n",
    "countries = [\"Africa\", \"US\", \"China\", \"EU\", \"Russia\", \"Ukraine\", \"Middle East\"]  # List of countries to search for\n",
    "\n",
    "# Initialize counts for each country\n",
    "country_counts = {country: 0 for country in countries}\n",
    "\n",
    "# Iterate over each article and count mentions of countries\n",
    "for content in articles_df['content']:\n",
    "    for country in countries:\n",
    "        # Count occurrences of the country in the content\n",
    "        country_counts[country] += len(re.findall(r'\\b{}\\b'.format(country), str(content), re.IGNORECASE))\n",
    "\n",
    "# Convert counts to DataFrame for easier manipulation\n",
    "country_counts_df = pd.DataFrame.from_dict(country_counts, orient='index', columns=['Count'])\n",
    "\n",
    "# Get the top and bottom ten countries with many articles written about them\n",
    "top_ten_countries_articles = country_counts_df.nlargest(10, 'Count')\n",
    "bottom_ten_countries_articles = country_counts_df.nsmallest(10, 'Count')\n",
    "\n",
    "# Print top ten countries with many articles written about them\n",
    "print(\"Top Ten Countries with Many Articles Written About Them:\")\n",
    "print(top_ten_countries_articles)\n",
    "\n",
    "# Print bottom ten countries with few articles written about them\n",
    "print(\"\\nBottom Ten Countries with Few Articles Written About Them:\")\n",
    "print(bottom_ten_countries_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten African Countries with Websites Reporting News Content:\n",
      "              Count\n",
      "Niger           805\n",
      "Nigeria         674\n",
      "South Africa    297\n",
      "Egypt           167\n",
      "Mali            148\n",
      "Kenya           132\n",
      "Sudan           113\n",
      "Ethiopia         62\n",
      "Morocco          55\n",
      "Liberia          54\n",
      "\n",
      "Bottom Ten African Countries with Websites Reporting News Content:\n",
      "                       Count\n",
      "Congo (Brazzaville)        0\n",
      "Congo (Kinshasa)           0\n",
      "Sao Tome and Principe      0\n",
      "Burundi                    1\n",
      "Cabo Verde                 1\n",
      "Comoros                    1\n",
      "Cote d'Ivoire              1\n",
      "Eswatini                   1\n",
      "Mauritania                 1\n",
      "Djibouti                   2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data containing information about websites and reported countries\n",
    "data_dir = '../data'  # Adjust path as per your directory structure\n",
    "articles_df = pd.read_csv(f\"{data_dir}/rating.csv\")  # Assuming the dataset is in CSV format\n",
    "\n",
    "# Define the African countries\n",
    "african_countries = ['Algeria', 'Angola', 'Benin', 'Botswana', 'Burkina Faso', 'Burundi', 'Cabo Verde', 'Cameroon', 'Central African Republic', 'Chad', 'Comoros', 'Congo (Brazzaville)', 'Congo (Kinshasa)', \"Cote d'Ivoire\", 'Djibouti', 'Egypt', 'Equatorial Guinea', 'Eritrea', 'Eswatini', 'Ethiopia', 'Gabon', 'Gambia', 'Ghana', 'Guinea', 'Guinea-Bissau', 'Kenya', 'Lesotho', 'Liberia', 'Libya', 'Madagascar', 'Malawi', 'Mali', 'Mauritania', 'Mauritius', 'Morocco', 'Mozambique', 'Namibia', 'Niger', 'Nigeria', 'Rwanda', 'Sao Tome and Principe', 'Senegal', 'Seychelles', 'Sierra Leone', 'Somalia', 'South Africa', 'South Sudan', 'Sudan', 'Tanzania', 'Togo', 'Tunisia', 'Uganda', 'Zambia', 'Zimbabwe']\n",
    "\n",
    "# Initialize counts for each African country\n",
    "african_country_counts = {country: 0 for country in african_countries}\n",
    "\n",
    "# Iterate over each article and count websites reporting news content for each African country\n",
    "for index, row in articles_df.iterrows():\n",
    "    for country in african_countries:\n",
    "        # Check if the country is mentioned in the article content\n",
    "        if country.lower() in row['content'].lower():\n",
    "            african_country_counts[country] += 1\n",
    "\n",
    "# Convert counts to DataFrame for easier manipulation\n",
    "african_country_counts_df = pd.DataFrame.from_dict(african_country_counts, orient='index', columns=['Count'])\n",
    "\n",
    "# Get the top and bottom ten African countries with websites reporting news content\n",
    "top_ten_african_countries = african_country_counts_df.nlargest(10, 'Count')\n",
    "bottom_ten_african_countries = african_country_counts_df.nsmallest(10, 'Count')\n",
    "\n",
    "# Print top ten African countries with websites reporting news content\n",
    "print(\"Top Ten African Countries with Websites Reporting News Content:\")\n",
    "print(top_ten_african_countries)\n",
    "\n",
    "# Print bottom ten African countries with websites reporting news content\n",
    "print(\"\\nBottom Ten African Countries with Websites Reporting News Content:\")\n",
    "print(bottom_ten_african_countries)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
